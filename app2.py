import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import platform
from matplotlib import font_manager, rc
import requests # TMDB API í˜¸ì¶œì„ ìœ„í•´ ì¶”ê°€

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# sentence_transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
# pip install -U sentence-transformers
from sentence_transformers import SentenceTransformer

# --- 1. ê¸°ë³¸ ì„¤ì • ë° í°íŠ¸ ---

def setup_korean_font():
    """
    ìš´ì˜ì²´ì œì— ë§ëŠ” í•œê¸€ í°íŠ¸ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
    """
    if platform.system() == 'Windows':
        font_name = font_manager.FontProperties(fname="c:/Windows/Fonts/malgun.ttf").get_name()
        rc('font', family=font_name)
    elif platform.system() == 'Darwin': # macOS
        rc('font', family='AppleGothic')
    else: # Linux
        font_path = "/usr/share/fonts/truetype/nanum/NanumGothic.ttf"
        if font_manager.findfont(font_path):
            rc('font', family='NanumGothic')
        else:
            rc('font', family='DejaVu Sans')
    plt.rcParams['axes.unicode_minus'] = False

setup_korean_font()

st.set_page_config(page_title="ì˜í™” ì˜ˆì¸¡ ì‹œìŠ¤í…œ", layout="wide")
st.title("ğŸ¬ ì˜í™” ì˜ˆì¸¡ ì‹œìŠ¤í…œ")
st.markdown("---")

# --- 2. ë°ì´í„° ë° API ê´€ë ¨ í•¨ìˆ˜ ---

@st.cache_data(show_spinner="ì˜í™” ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤...")
def load_data(file_path):
    """
    CSV íŒŒì¼ì—ì„œ ì˜í™” ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ê¸°ë³¸ ì „ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    df = pd.read_csv(file_path)
    for col in ['ëˆ„ì ê´€ê°ìˆ˜', 'ëˆ„ì ë§¤ì¶œì•¡']:
        df[col] = pd.to_numeric(df[col], errors='coerce')
    df['ê°œë´‰ì¼'] = pd.to_datetime(df['ê°œë´‰ì¼'], errors='coerce', format='%Y-%m-%d')
    df.dropna(subset=['ëˆ„ì ê´€ê°ìˆ˜', 'ëˆ„ì ë§¤ì¶œì•¡', 'ê°œë´‰ì¼', 'ê°ë…', 'ì¥ë¥´', 'ì œì‘êµ­ê°€'], inplace=True)
    df['ê°œë´‰_ì›”'] = df['ê°œë´‰ì¼'].dt.month
    df['ê°œë´‰_ë…„'] = df['ê°œë´‰ì¼'].dt.year
    df['text_for_tfidf'] = df[['ê°ë…', 'ì œì‘êµ­ê°€', 'ì¥ë¥´']].astype(str).agg(' '.join, axis=1)
    df['text_for_kobert'] = df.apply(
        lambda row: f"{row['ê°ë…']} ê°ë…ì´ ì œì‘í•œ {row['ì œì‘êµ­ê°€']} ì˜í™”. ì¥ë¥´ëŠ” {row['ì¥ë¥´']}ì´ë©°, {row['ê°œë´‰_ë…„']}ë…„ {row['ê°œë´‰_ì›”']}ì›”ì— ê°œë´‰í–ˆìŠµë‹ˆë‹¤.",
        axis=1
    )
    return df

@st.cache_data(show_spinner=False) # API í˜¸ì¶œ ê²°ê³¼ë¥¼ ìºì‹±í•©ë‹ˆë‹¤.
def get_movie_poster_url(movie_title):
    """
    TMDB APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜í™” í¬ìŠ¤í„° URLì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    """
    API_KEY = "62fd419c4be9316756c61d72694907d3" # ì œê³µëœ API í‚¤
    search_url = f"https://api.themoviedb.org/3/search/movie?api_key={API_KEY}&query={movie_title}&language=ko-KR"
    try:
        response = requests.get(search_url)
        response.raise_for_status() # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì˜ˆì™¸ ì²˜ë¦¬
        data = response.json()
        if data['results']:
            poster_path = data['results'][0].get('poster_path')
            if poster_path:
                return f"https://image.tmdb.org/t/p/w500{poster_path}"
    except requests.exceptions.RequestException as e:
        # st.error(f"API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}") # ë””ë²„ê¹… ì‹œ ì‚¬ìš©
        pass
    return "https://placehold.co/300x450/cccccc/000000?text=No+Image" # ì´ë¯¸ì§€ê°€ ì—†ì„ ê²½ìš°

# ë°ì´í„° ë¡œë“œ
df = load_data("data/20-25ë…„_ì˜í™”ë°ì´í„°_í•œê¸€ì»¬ëŸ¼.csv")
title_to_index = pd.Series(df.index, index=df['ì˜í™”ëª…']).drop_duplicates()

# --- 3. ì¶”ì²œ ëª¨ë¸ (TF-IDF & KoBERT) ---

@st.cache_resource(show_spinner="TF-IDF ìœ ì‚¬ë„ ëª¨ë¸ì„ ê³„ì‚°í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤...")
def get_tfidf_similarity_matrix(dataframe):
    tfidf = TfidfVectorizer(min_df=2)
    tfidf_matrix = tfidf.fit_transform(dataframe['text_for_tfidf'])
    return cosine_similarity(tfidf_matrix, tfidf_matrix)

@st.cache_resource(show_spinner="KoBERT ì„ë² ë”© ë° ìœ ì‚¬ë„ ëª¨ë¸ì„ ê³„ì‚°í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤...")
def get_kobert_similarity_matrix(dataframe):
    model = SentenceTransformer('snunlp/KR-SBERT-V40K-klueNLI-augSTS')
    embeddings = model.encode(dataframe['text_for_kobert'].tolist(), convert_to_tensor=False, show_progress_bar=True)
    return cosine_similarity(embeddings, embeddings)

cosine_sim_tfidf = get_tfidf_similarity_matrix(df)
cosine_sim_kobert = get_kobert_similarity_matrix(df)

def get_recommendations(title, similarity_matrix, top_n=5):
    idx = title_to_index.get(title)
    if idx is None: return None
    sim_scores = sorted(list(enumerate(similarity_matrix[idx])), key=lambda x: x[1], reverse=True)[1:top_n+1]
    movie_indices = [i[0] for i in sim_scores]
    
    # ì¶”ì²œëœ ì˜í™” ì •ë³´ì™€ í•¨ê»˜ í¬ìŠ¤í„° URLë„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    recommended_df = df.iloc[movie_indices][['ì˜í™”ëª…', 'ê°ë…', 'ì¥ë¥´', 'ê°œë´‰ì¼']].copy()
    recommended_df['í¬ìŠ¤í„°'] = recommended_df['ì˜í™”ëª…'].apply(get_movie_poster_url)
    return recommended_df[['í¬ìŠ¤í„°', 'ì˜í™”ëª…', 'ê°ë…', 'ì¥ë¥´', 'ê°œë´‰ì¼']]

# --- 4. Streamlit UI - ì˜í™” ì¶”ì²œ ---

st.header("âœ¨ ì½˜í…ì¸  ê¸°ë°˜ ì˜í™” ì¶”ì²œ")
st.write("ì˜í™”ë¥¼ ì„ íƒí•˜ë©´ í•´ë‹¹ ì˜í™”ì˜ í¬ìŠ¤í„°ì™€ ì •ë³´, ê·¸ë¦¬ê³  ë‘ ê°€ì§€ ë°©ì‹ìœ¼ë¡œ ì¶”ì²œëœ ì˜í™” ëª©ë¡ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.")

movie_list = ['ì˜í™”ë¥¼ ì„ íƒí•˜ì„¸ìš”...'] + sorted(df['ì˜í™”ëª…'].unique().tolist())
selected_movie = st.selectbox("ì¶”ì²œì˜ ê¸°ì¤€ì´ ë  ì˜í™”ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”:", movie_list)

if selected_movie != 'ì˜í™”ë¥¼ ì„ íƒí•˜ì„¸ìš”...':
    st.markdown("---")
    movie_info = df[df['ì˜í™”ëª…'] == selected_movie].iloc[0]
    
    # ì„ íƒëœ ì˜í™” ì •ë³´ (í¬ìŠ¤í„°ì™€ í•¨ê»˜)
    st.subheader(f"'{selected_movie}' ì •ë³´")
    col1, col2 = st.columns([1, 2])
    with col1:
        st.image(get_movie_poster_url(selected_movie), use_column_width=True)
    with col2:
        st.info(f"**ê°ë…:** {movie_info['ê°ë…']}")
        st.info(f"**ì¥ë¥´:** {movie_info['ì¥ë¥´']}")
        st.info(f"**ì œì‘êµ­ê°€:** {movie_info['ì œì‘êµ­ê°€']}")
        st.info(f"**ê°œë´‰ì¼:** {movie_info['ê°œë´‰ì¼'].date()}")
        st.info(f"**ëˆ„ì  ê´€ê°ìˆ˜:** {int(movie_info['ëˆ„ì ê´€ê°ìˆ˜']):,} ëª…")
        st.info(f"**ëˆ„ì  ë§¤ì¶œì•¡:** â‚© {int(movie_info['ëˆ„ì ë§¤ì¶œì•¡']):,}")

    st.markdown("---")
    st.subheader(f"'{selected_movie}'ì™€ ë¹„ìŠ·í•œ ì˜í™” ì¶”ì²œ ëª©ë¡")
    
    # ì¶”ì²œ ê²°ê³¼ (í¬ìŠ¤í„°ì™€ í•¨ê»˜)
    col1, col2 = st.columns(2)
    with col1:
        st.markdown("#### ğŸ¤– TF-IDF ê¸°ë°˜ ì¶”ì²œ (í‚¤ì›Œë“œ ì¤‘ì‹¬)")
        rec_tfidf = get_recommendations(selected_movie, cosine_sim_tfidf)
        if rec_tfidf is not None:
            st.data_editor(rec_tfidf, column_config={"í¬ìŠ¤í„°": st.column_config.ImageColumn("í¬ìŠ¤í„°")}, hide_index=True, use_container_width=True)
        else:
            st.warning("ì¶”ì²œ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    with col2:
        st.markdown("#### ğŸ§  KoBERT ê¸°ë°˜ ì¶”ì²œ (ì˜ë¯¸ ì¤‘ì‹¬)")
        rec_kobert = get_recommendations(selected_movie, cosine_sim_kobert)
        if rec_kobert is not None:
            st.data_editor(rec_kobert, column_config={"í¬ìŠ¤í„°": st.column_config.ImageColumn("í¬ìŠ¤í„°")}, hide_index=True, use_container_width=True)
        else:
            st.warning("ì¶”ì²œ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

st.markdown("\n\n---\n\n")

# --- 5. Streamlit UI - ê´€ê°ìˆ˜ ì˜ˆì¸¡ ---

st.header("ğŸ¯ ëˆ„ì  ê´€ê°ìˆ˜ ì˜ˆì¸¡ ëª¨ë¸")
with st.spinner("ê´€ê°ìˆ˜ ì˜ˆì¸¡ ëª¨ë¸ì„ í•™ìŠµí•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
    X = df[['ëˆ„ì ë§¤ì¶œì•¡', 'ê°œë´‰_ì›”', 'ì¥ë¥´', 'ì œì‘êµ­ê°€']]
    y = df['ëˆ„ì ê´€ê°ìˆ˜']
    numerical_features = ['ëˆ„ì ë§¤ì¶œì•¡']
    categorical_features = ['ê°œë´‰_ì›”', 'ì¥ë¥´', 'ì œì‘êµ­ê°€']
    preprocessor = ColumnTransformer(transformers=[
        ('num', StandardScaler(), numerical_features),
        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)],
        remainder='passthrough')
    model_pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('regressor', RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1))])
    test_size_val = max(0.2, 1 / len(X) if len(X) > 0 else 0.2)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size_val, random_state=42)
    model_pipeline.fit(X_train, y_train)
    y_pred = model_pipeline.predict(X_test)
    mse, rmse, r2 = mean_squared_error(y_test, y_pred), np.sqrt(mean_squared_error(y_test, y_pred)), r2_score(y_test, y_pred)

st.subheader("ğŸ“Š ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œ")
col1, col2, col3 = st.columns(3)
col1.metric("MSE", f"{mse:,.0f}")
col2.metric("RMSE", f"{rmse:,.0f}")
col3.metric("RÂ² Score", f"{r2:.4f}")

st.subheader("ğŸ“ˆ ì‹¤ì œ vs ì˜ˆì¸¡ ê´€ê°ìˆ˜ ì‹œê°í™”")
fig, ax = plt.subplots(figsize=(10, 6))
sns.scatterplot(x=y_test, y=y_pred, alpha=0.6, ax=ax, color='royalblue')
ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2, label='ì´ìƒì ì¸ ì˜ˆì¸¡')
ax.set_xlabel("ì‹¤ì œ ëˆ„ì  ê´€ê°ìˆ˜")
ax.set_ylabel("ì˜ˆì¸¡ ëˆ„ì  ê´€ê°ìˆ˜")
ax.set_title("ëœë¤ í¬ë ˆìŠ¤íŠ¸ íšŒê·€: ì‹¤ì œ vs ì˜ˆì¸¡")
ax.legend()
ax.grid(True)
ax.get_xaxis().set_major_formatter(plt.FuncFormatter(lambda x, loc: "{:,}".format(int(x))))
ax.get_yaxis().set_major_formatter(plt.FuncFormatter(lambda x, loc: "{:,}".format(int(x))))
plt.xticks(rotation=45)
st.pyplot(fig)
